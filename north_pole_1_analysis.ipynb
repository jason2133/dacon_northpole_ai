{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"north_pole_1_analysis.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN2JbLjdosChQ1/mR5lcxl4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"DQ5R1cR-cAg-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615878426721,"user_tz":-540,"elapsed":17505,"user":{"displayName":"‍이재승[ 학부휴학 / 통계학과 ]","photoUrl":"","userId":"07334189714045208317"}},"outputId":"399de94a-aa7c-4bf1-b6ec-7fbefd867b05"},"source":["# 구글 드라이브 연동\r\n","\r\n","from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pdIV0UaYheUG"},"source":["# 모듈들 import\r\n","\r\n","import os\r\n","from glob import glob\r\n","import copy\r\n","\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import pandas as pd\r\n","\r\n","from sklearn.model_selection import train_test_split\r\n","from sklearn.preprocessing import MinMaxScaler\r\n","\r\n","import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","from torch import optim\r\n","from torch.utils.data import Dataset, DataLoader, random_split\r\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\r\n","\r\n","from torchvision import transforms, utils\r\n","from torchsummary import summary"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ydf1v4frheWd","executionInfo":{"status":"ok","timestamp":1615878435518,"user_tz":-540,"elapsed":853,"user":{"displayName":"‍이재승[ 학부휴학 / 통계학과 ]","photoUrl":"","userId":"07334189714045208317"}},"outputId":"529bee67-0352-47aa-962d-4f25db37087b"},"source":["# GPU\r\n","\r\n","device = None\r\n","\r\n","if torch.cuda.is_available():\r\n","  device = torch.device('cuda')\r\n","else:\r\n","  device = torch.device('cpu')\r\n","\r\n","print('Using PyTorch version:', torch.__version__, 'Device:', device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using PyTorch version: 1.8.0+cu101 Device: cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jK0FyFcdheYp","executionInfo":{"status":"ok","timestamp":1615878438465,"user_tz":-540,"elapsed":828,"user":{"displayName":"‍이재승[ 학부휴학 / 통계학과 ]","photoUrl":"","userId":"07334189714045208317"}},"outputId":"0fb996eb-cd8d-47b8-d03b-a42f5643d32b"},"source":["# 데이터 불러오기\r\n","\r\n","data_path = './drive/MyDrive/northpole/data/'\r\n","train_data_path = os.path.join(data_path, \"train\")\r\n","\r\n","print(train_data_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["./drive/MyDrive/northpole/data/train\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7kP5Dx5Nhean"},"source":["# train data 파일 리스트 정렬\r\n","\r\n","file_list = os.listdir(train_data_path)\r\n","file_list.sort()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MxQweADvm5uy","executionInfo":{"status":"ok","timestamp":1615878448038,"user_tz":-540,"elapsed":4569,"user":{"displayName":"‍이재승[ 학부휴학 / 통계학과 ]","photoUrl":"","userId":"07334189714045208317"}},"outputId":"a80b4c94-39f7-4d36-cec7-00c7a6e302c2"},"source":["## Custom Dataset which return x_frames, y_frames\r\n","\r\n","torch.set_printoptions(threshold=10000)\r\n","# show all tensor without abbreviation\r\n","# 설명은 여기에 https://pytorch.org/docs/stable/generated/torch.set_printoptions.html\r\n","\r\n","\r\n","# 482장의 데이터파일을 8개씩 묶어 6장을 통해 뒤의 2장을 예측할 수 있도록 분리하여 저장\r\n","\r\n","class SeaIceDataset(Dataset):\r\n","    def __init__(self, data_dir, transform, data_type=\"train\", frame_num=6, predict_num=2, stride=1):\r\n","        super(SeaIceDataset, self).__init__()\r\n","\r\n","        \"\"\"\r\n","        data_dir                => data folder path\r\n","        transform               => data to tensor\r\n","\r\n","        data_type=\"train\"       => choose train / valid / test\r\n","        그치. data_dir랑 data_type를 합칠거니까.\r\n","\r\n","        482장의 데이터파일을 8개씩 묶어 6장을 통해 뒤의 2장을 예측할 수 있도록 분리하여 저장\r\n","\r\n","        frame_num               => frame nums to use on train \r\n","        # 이거 6장이랑\r\n","        \r\n","        predict_num             => frame nums to predict\r\n","        # 이거 2장\r\n","\r\n","        stride_num              => stride for frames (if stride=2 => 197811.npy, 198001.npy, 198003.npy ... )\r\n","                                만약 8월끼리 비교하고 싶다면 stride = 12 를 넣어준다.  \r\n","        \"\"\"\r\n","\r\n","        # 데이터 경로 지정해주고.\r\n","        data_to_path = os.path.join(data_dir, data_type)\r\n","        \r\n","        # 파일 이름 불러오고\r\n","        filenames = os.listdir(data_to_path)\r\n","        \r\n","        # 파일 각각을 불러오려고\r\n","        # sorted(filenames)를 통해 파일이 정렬된 상태에서 파일 각각을 불러옴.\r\n","        self.filepaths = [os.path.join(data_to_path, filename) for filename in sorted(filenames)]\r\n","        \r\n","        # Numpy 배열을 Tensor 배열로 바꿔주는 함수\r\n","        self.transform = transform\r\n","\r\n","        self.frame_num = frame_num \r\n","        self.predict_num = predict_num\r\n","        self.stride = stride\r\n","\r\n","    def __len__(self):\r\n","        # len = dataset으로 시작가능한 인덱스 번호 \r\n","        return len(self.filepaths) - (self.frame_num + self.predict_num - 1) * self.stride\r\n","    \r\n","    def __getitem__(self, idx):\r\n","        \"\"\"\r\n","        it will return (x_with_frame_num, y_true_with_predict_num)\r\n","        if frame_num = 6, predict_num = 2\r\n","        ((6, 1, 448, 304), (2, 1, 448, 304))\r\n","        \"\"\"\r\n","        dataset = []\r\n","\r\n","        # idx부터 idx + 6 + 2로, stride만큼 진행해준다. stride를 1로 지정함.\r\n","        for id in range(idx, idx + self.frame_num + self.predict_num, self.stride):\r\n","\r\n","            cur_npy = np.load(self.filepaths[id])[:,:,0]/250    # 250을 나눠주어 저장하지 않으면 toTensor했을때 오차값이 크게 생겼습니다\r\n","            cur_tensor = self.transform(cur_npy)                # tensor로 저장\r\n","            dataset.append(cur_tensor)\r\n","\r\n","        # self.frame_num = 6이므로, :6 6개\r\n","        x = torch.stack(dataset[:self.frame_num])\r\n","        x = x.transpose(0,1).to(dtype=torch.float)              # [1, 6, 448, 304] => [channel, frames, height, width]\r\n","        # transpose는 2개의 차원을 변경하는데 사용\r\n","        # https://pytorch.org/docs/stable/generated/torch.transpose.html\r\n","\r\n","        # 원래 (6, 1, 448, 304)이었는데, 이걸 보기 쉽게 [1, 6, 448, 304]로 변경.\r\n","\r\n","        \r\n","        # 6부터 8까지, 2개 6:\r\n","        y = torch.stack(dataset[self.frame_num:])               \r\n","        y = y.transpose(0,1)                                    # [1, 2, 448, 304] => [channel, frames, height, width]\r\n","        \r\n","        # 원래 (2, 1, 448, 304)이었는데, 이걸 보기 쉽게 [1, 2, 448, 304]로 변경.\r\n","\r\n","        return x, y\r\n","\r\n","# Tensor 형식으로 transform\r\n","def getTransform():\r\n","    return transforms.Compose([transforms.ToTensor()])\r\n","\r\n","\r\n","\r\n","transform = getTransform()\r\n","\r\n","ice_dataset = SeaIceDataset(data_path, transform, \"train\", 6, 2, 1)\r\n","\r\n","a,b = ice_dataset[1]        # sample to see \r\n","print(len(ice_dataset))     # 데이터셋에 있는 총 데이터의 개수는 8개씩 묶여있는 475개의 데이터가 있습니다\r\n","print(a.shape, b.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["475\n","torch.Size([1, 6, 448, 304]) torch.Size([1, 2, 448, 304])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ndPjQWZUhee0","executionInfo":{"status":"ok","timestamp":1615878450882,"user_tz":-540,"elapsed":2081,"user":{"displayName":"‍이재승[ 학부휴학 / 통계학과 ]","photoUrl":"","userId":"07334189714045208317"}},"outputId":"21e9ec29-1307-4004-d81c-9c68dc6516d0"},"source":["a,b = ice_dataset[5]\r\n","print(len(ice_dataset))\r\n","print(a.shape, b.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["475\n","torch.Size([1, 6, 448, 304]) torch.Size([1, 2, 448, 304])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ZneVqVrhegz","executionInfo":{"status":"ok","timestamp":1615878452793,"user_tz":-540,"elapsed":784,"user":{"displayName":"‍이재승[ 학부휴학 / 통계학과 ]","photoUrl":"","userId":"07334189714045208317"}},"outputId":"53711639-0364-48ca-d912-9d1d804cb924"},"source":["# Data를 Train과 Valid로 나눈다.\r\n","# Train / Valid / Test로 나누는 이유는 overfitting을 방지하기 위함도 있음.\r\n","\r\n","len_ice_dataset = len(ice_dataset)\r\n","\r\n","len_ice_train = int(0.8 * len_ice_dataset)\r\n","len_ice_valid = len_ice_dataset - len_ice_train\r\n","\r\n","train_dataset, valid_dataset = random_split(ice_dataset, [len_ice_train, len_ice_valid])\r\n","# random_split은 말그대로 랜덤하게 데이터를 나누어주는것.\r\n","# https://pytorch.org/docs/stable/data.html\r\n","\r\n","print(f\"train dataset length : {len(train_dataset)}\")\r\n","print(f\"valid dataset length : {len(valid_dataset)}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train dataset length : 380\n","valid dataset length : 95\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0EBBAZWChei9","executionInfo":{"status":"ok","timestamp":1615878491016,"user_tz":-540,"elapsed":29320,"user":{"displayName":"‍이재승[ 학부휴학 / 통계학과 ]","photoUrl":"","userId":"07334189714045208317"}},"outputId":"00e3322b-f191-47c7-eda3-46441d589618"},"source":["BATCH_SIZE = 12\r\n","\r\n","# Dataloader 클래스는 데이터셋에서 배치 개수만큼 뽑아서 제공해줌.\r\n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\r\n","valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\r\n","\r\n","# train_dataloader length => 32\r\n","# 32 * 12 = 384이므로. train data는 380개잖아.\r\n","\r\n","for x, y in train_dataloader:\r\n","  print(x.shape, y.shape)\r\n","  break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([12, 1, 6, 448, 304]) torch.Size([12, 1, 2, 448, 304])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_JIrj1w6helH"},"source":["MODEL_PARAMS = {\r\n","    \"shape\": (6, 1, 448, 304),\r\n","    \"init_filters\":8,\r\n","    \"dropout_rate\":0.5\r\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w3IndWMV3bJI"},"source":["# Creating Model\r\n","\r\n","class CustomNet(nn.Module):\r\n","  def __init__(self, params):\r\n","    super(CustomNet, self).__init__()\r\n","    input_frames, input_channel, input_height, input_width = params[\"shape\"]\r\n","    init_filters = params[\"init_filters\"]\r\n","    self.dropout_rate = params[\"dropout_rate\"]\r\n","    self.conv1 = nn.Conv3d(input_channel, init_filters, kernel_size=3, padding=1)\r\n","    self.conv2 = nn.Conv3d(init_filters, init_filters*2, kernel_size=3, padding=1)\r\n","    self.conv3 = nn.ConvTranspose3d(init_filters*2, 1, kernel_size=3, padding=1)\r\n","\r\n","  def forward(self, x):\r\n","    input = x\r\n","    x = F.relu(self.conv1(x))\r\n","    x = F.max_pool3d(x, 2, 2)\r\n","    x = F.relu(self.conv2(x))\r\n","    x = F.relu(self.conv3(x))\r\n","    x = F.upsample(x, size=(2, 448, 304))\r\n","    print(\"input: \", input.shape)\r\n","    print(\"output: \", x.shape)\r\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WwYps-ep3bLW","executionInfo":{"status":"ok","timestamp":1615880136386,"user_tz":-540,"elapsed":11296,"user":{"displayName":"‍이재승[ 학부휴학 / 통계학과 ]","photoUrl":"","userId":"07334189714045208317"}},"outputId":"2bcee702-8f1e-48ce-a73e-ce6000e44995"},"source":["my_model = CustomNet(MODEL_PARAMS).to(device)\r\n","print(my_model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CustomNet(\n","  (conv1): Conv3d(1, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","  (conv2): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","  (conv3): ConvTranspose3d(16, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2xi_MIM63bNe","executionInfo":{"status":"ok","timestamp":1615880162574,"user_tz":-540,"elapsed":772,"user":{"displayName":"‍이재승[ 학부휴학 / 통계학과 ]","photoUrl":"","userId":"07334189714045208317"}},"outputId":"efb00c87-2862-4e7e-be09-c1ab6dc35c62"},"source":["# summary 함수를 통해 임의의 사이즈를 넣어 구조와 파라미터를 확인함\r\n","\r\n","summary(my_model, input_size=(1, 6, 448, 304), device=device.type)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["input:  torch.Size([2, 1, 6, 448, 304])\n","output:  torch.Size([2, 1, 2, 448, 304])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv3d-1       [-1, 8, 6, 448, 304]             224\n","            Conv3d-2      [-1, 16, 3, 224, 152]           3,472\n","   ConvTranspose3d-3       [-1, 1, 3, 224, 152]             433\n","================================================================\n","Total params: 4,129\n","Trainable params: 4,129\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 3.12\n","Forward/backward pass size (MB): 63.12\n","Params size (MB): 0.02\n","Estimated Total Size (MB): 66.26\n","----------------------------------------------------------------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3325: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n","  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Ks96VhtbSx8o"},"source":["### 이 부분은 산식코드로 제공이 된 코드임."]},{"cell_type":"code","metadata":{"id":"mIdKW1mU3bPT"},"source":["# 음 이 부분은 산식코드로 제공이 된 코드네.\r\n","\r\n","# Loss Function && etric Function\r\n","\r\n","# metrics\r\n","def mae_score(true, pred):\r\n","    true, pred = numpy_to_tensor(true, pred)\r\n","    score = np.mean(np.abs(true-pred))\r\n","    \r\n","    return score\r\n","\r\n","# F1 Score 설명\r\n","# https://eunsukimme.github.io/ml/2019/10/21/Accuracy-Recall-Precision-F1-score/\r\n","\r\n","def f1_score(true, pred):\r\n","    true, pred = numpy_to_tensor(true, pred)\r\n","\r\n","    target = np.where((1*0.05 < true)&(true < 1*0.5))\r\n","    # target = np.where((true>1*0.05)<1*0.5))\r\n","    \r\n","    true = true[target]\r\n","    pred = pred[target]\r\n","\r\n","    # true가 1*0.15보다 작을 경우 0을, 아니면 1을 반환\r\n","    true = np.where(true < 1*0.15, 0, 1)\r\n","\r\n","    # pred가 1*0.15보다 작을 경우 0을, 아니면 1을 반환\r\n","    pred = np.where(pred < 1*0.15, 0, 1)\r\n","    \r\n","    # true * pred == 1인 모든 값을 더해줌.\r\n","    right = np.sum(true * pred == 1)\r\n","    \r\n","    # Precision은 모델이 True로 예측한 데이터 중 실제로 True인 데이터의 수\r\n","    # precision = TruePositives / (TruePositives + FalsePositives)\r\n","    precision = right / np.sum(true+1e-8)\r\n","\r\n","    # recall은 실제로 True인 데이터를 True라고 인식한 데이터 수\r\n","    # recall = TruePositives / (TruePositives + FalseNegatives)\r\n","    recall = right / np.sum(pred+1e-8)\r\n","\r\n","    # F1 score는 precision 과 recall의 조화평균\r\n","    # 2 * (precision * recall / precision + recall)\r\n","    score = 2 * precision*recall/(precision+recall+1e-8)\r\n","    \r\n","    return score\r\n","\r\n","# loss function\r\n","def mae_over_f1(true, pred):\r\n","    mae = mae_score(true, pred)\r\n","    f1 = f1_score(true, pred)\r\n","    score = mae/(f1+1e-8)\r\n","    \r\n","    return score\r\n","\r\n","def numpy_to_tensor(true, pred):\r\n","    return true.cpu().detach().numpy(), pred.cpu().detach().numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-f6AHq6EhenK","executionInfo":{"status":"ok","timestamp":1615881036252,"user_tz":-540,"elapsed":857,"user":{"displayName":"‍이재승[ 학부휴학 / 통계학과 ]","photoUrl":"","userId":"07334189714045208317"}},"outputId":"14a8f20e-4a31-4a24-9720-ee40621f7021"},"source":["# Optimizer - Adam\r\n","\r\n","# Adam\r\n","opt_adam = optim.Adam(my_model.parameters(), lr=3e-4)\r\n","\r\n","def get_lr(opt):\r\n","  for param_group in opt.param_groups:\r\n","    return param_group[\"lr\"]\r\n","  \r\n","current_lr = get_lr(opt_adam)\r\n","print(f\"current_lr = {current_lr}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["current_lr = 0.0003\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XblNSF_ChepV"},"source":["# learning rate scheduler\r\n","lr_scheduler = ReduceLROnPlateau(opt_adam, mode=\"min\", factor=0.5, patience=20, verbose=1)\r\n","\r\n","# https://deep-deep-deep.tistory.com/56\r\n","# 모델의 개선이 없을 경우, Learning Rate를 조절해 모델의 개선을 유도하는 콜백함수\r\n","\r\n","# monitor : ReduceLROnPlateau의 기준이 되는 값\r\n","\r\n","# mode : min / max / auto - monitor 되는 값이 최대가 되어야 하는지, 최소가 되어야 하는지 결정.\r\n","\r\n","# factor : Learning rate를 얼마나 감소시킬지 정하는 인자값\r\n","# 새로운 learning rate는 기존 learning rate * factor임.\r\n","\r\n","# patience : Training이 진행됨에도 더이상 monitor되는 값의 개선이 없을 경우, \r\n","# 최적의 monitor 값을 기준으로 몇 번의 epoch을 진행하고, learning rate를 조절할 지의 값\r\n","# 예를 들어 patience는 3이고, 30에폭에 정확도가 99%였을 때,\r\n","# 만약 31번째에 정확도 98%, 32번째에 98.5%, 33번째에 98%라면 \r\n","# 모델의 개선이 (patience=3)동안 개선이 없었기에,  \r\n","# ReduceLROnPlateau 콜백함수를 실행함.\r\n","\r\n","# verbose : 0 또는 1\r\n","# 1일 경우, EarlyStopping이 적용될 때 화면에 적용되었다고 나타냄.\r\n","# 0일 경우, 화면에 나타냄 없이 종료. \r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t9TiWlJ8herz","executionInfo":{"status":"ok","timestamp":1615881039968,"user_tz":-540,"elapsed":769,"user":{"displayName":"‍이재승[ 학부휴학 / 통계학과 ]","photoUrl":"","userId":"07334189714045208317"}},"outputId":"5a6afdab-e4b8-4b5e-9148-e2e805b42acb"},"source":["for i in range(100):\r\n","  lr_scheduler.step(1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch    22: reducing learning rate of group 0 to 1.5000e-04.\n","Epoch    43: reducing learning rate of group 0 to 7.5000e-05.\n","Epoch    64: reducing learning rate of group 0 to 3.7500e-05.\n","Epoch    85: reducing learning rate of group 0 to 1.8750e-05.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XBlaCLCR_axR"},"source":["# Training \r\n","\r\n","def metrics_batch(pred, true, metrics):\r\n","    # if needed add param \"metrics\" to custom\r\n","    \"\"\"\r\n","    output will be pred\r\n","    target will be corrects\r\n","    \"\"\"\r\n","    if metrics:\r\n","        return list(map(lambda x: x(true, pred), metrics))\r\n","    mae_score = mae_score(true, pred)\r\n","    f1_score = f1_score(true, pred)\r\n","    return (mae_score, f1_score)\r\n","\r\n","def loss_batch(loss_func, pred, true, opt=None):\r\n","    \"\"\"\r\n","    loss_func => mae_over_f1\r\n","    \"\"\"\r\n","    loss = loss_func(true, pred)\r\n","    with torch.no_grad():\r\n","        metrics = metrics_batch(pred, true, [mae_score, f1_score])\r\n","    if opt is not None:\r\n","        opt.zero_grad()\r\n","        # loss.backward()\r\n","        opt.step()  # 학습이 이뤄지는 곳\r\n","    return loss, metrics\r\n","\r\n","def loss_epoch(model, loss_func, dataset_dataloader, sanity_check=False, opt=None):\r\n","    running_loss = 0.0\r\n","    running_metric = [0.0, 0.0]\r\n","    len_data = len(dataset_dataloader.dataset)\r\n","\r\n","    for x, y in dataset_dataloader:\r\n","        x = x.to(device)\r\n","        y = y.to(device)\r\n","        # 모델 결과\r\n","        pred = model(x)\r\n","        # 손실함수 구하기\r\n","        loss, metrics = loss_batch(loss_func, pred, y, opt)\r\n","        # 손실함수 \r\n","        running_loss += loss\r\n","        if metrics is not None:\r\n","            for idx, metric_value in enumerate(metrics):\r\n","                running_metric[idx] += metric_value\r\n","        \r\n","        # 문제 있으면 break, 여기서는 True 일때 바로 break\r\n","        if sanity_check is True:\r\n","            break\r\n","    \r\n","    loss = running_loss / float(len_data)\r\n","    metrics = list(map(lambda x: x/float(len_data), metrics))\r\n","    print(loss, metrics)\r\n","    return loss, metrics"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AY8uUOoe_azw"},"source":["loss_func = mae_over_f1\r\n","opt_adam = optim.Adam(my_model.parameters(), lr=3e-4)\r\n","lr_scheduler = ReduceLROnPlateau(opt_adam, mode=\"min\", factor=0.5, patience=20, verbose=1)\r\n","\r\n","TRAIN_PARAMS = {\r\n","    \"num_epochs\" : 10,\r\n","    \"loss_func\" : loss_func,\r\n","    \"optimizer\" : opt_adam,\r\n","    \"train_dataloader\" : train_dataloader,\r\n","    \"valid_dataloader\" : valid_dataloader,\r\n","    \"sanity_check\" : True,\r\n","    \"lr_scheduler\" : lr_scheduler,\r\n","    \"save_path\" : \"./weights.pt\"\r\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2SR9DB8_a1s"},"source":["def train(model, params):\r\n","    num_epochs = params['num_epochs']\r\n","    loss_func = params['loss_func']\r\n","    opt = params[\"optimizer\"]\r\n","    train_dataloader = params['train_dataloader']\r\n","    valid_dataloader = params['valid_dataloader']\r\n","    sanity_check = params['sanity_check']\r\n","    lr_scheduler = params['lr_scheduler']\r\n","    save_path = params['save_path']\r\n","\r\n","    # keep history of the loss and metric\r\n","    loss_hist = {\r\n","        \"train\" : [],\r\n","        \"valid\" : []\r\n","    }\r\n","\r\n","    metrics_hist = {\r\n","        \"train\" : [],\r\n","        \"valid\" : []\r\n","    }\r\n","\r\n","    # copy best weights\r\n","    best_model_weights = copy.deepcopy(model.state_dict())\r\n","    # init best loss\r\n","    best_loss = float(\"inf\")\r\n","\r\n","    for epoch in range(num_epochs):\r\n","        current_lr = get_lr(opt)\r\n","        print(f'Epoch:{epoch}/{num_epochs-1}, current lr:{current_lr}')\r\n","        model.train()\r\n","        train_loss, train_metrics = loss_epoch(model, loss_func, train_dataloader, sanity_check, opt)\r\n","\r\n","        # save history\r\n","        loss_hist[\"train\"].append(train_loss)\r\n","        metrics_hist[\"train\"].append(train_metrics)\r\n","\r\n","        # model.eval()\r\n","        # with torch.no_grad():\r\n","    \r\n","\r\n","    return model, loss_hist, metrics_hist"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p6eOBkD-_a3x","executionInfo":{"status":"ok","timestamp":1615881056987,"user_tz":-540,"elapsed":5933,"user":{"displayName":"‍이재승[ 학부휴학 / 통계학과 ]","photoUrl":"","userId":"07334189714045208317"}},"outputId":"53f879c0-52c6-42d3-e311-297b7e0a72db"},"source":["my_model, loss_hist, metrics_hist = train(my_model, TRAIN_PARAMS)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch:0/9, current lr:0.0003\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3325: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n","  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["input:  torch.Size([12, 1, 6, 448, 304])\n","output:  torch.Size([12, 1, 2, 448, 304])\n","0.03127452489467292 [0.00039106634236059763, 3.290605161973221e-05]\n","Epoch:1/9, current lr:0.0003\n","input:  torch.Size([12, 1, 6, 448, 304])\n","output:  torch.Size([12, 1, 2, 448, 304])\n","0.031274524891185866 [0.00039106634231699444, 3.290605161973221e-05]\n","Epoch:2/9, current lr:0.0003\n","input:  torch.Size([12, 1, 6, 448, 304])\n","output:  torch.Size([12, 1, 2, 448, 304])\n","0.031274524889158106 [0.0003910663422916387, 3.290605161973221e-05]\n","Epoch:3/9, current lr:0.0003\n","input:  torch.Size([12, 1, 6, 448, 304])\n","output:  torch.Size([12, 1, 2, 448, 304])\n","0.03127452488999857 [0.0003910663423021481, 3.290605161973221e-05]\n","Epoch:4/9, current lr:0.0003\n","input:  torch.Size([12, 1, 6, 448, 304])\n","output:  torch.Size([12, 1, 2, 448, 304])\n","0.03127452489040393 [0.00039106634230721683, 3.290605161973221e-05]\n","Epoch:5/9, current lr:0.0003\n","input:  torch.Size([12, 1, 6, 448, 304])\n","output:  torch.Size([12, 1, 2, 448, 304])\n","0.031274524891711154 [0.00039106634232356275, 3.290605161973221e-05]\n","Epoch:6/9, current lr:0.0003\n","input:  torch.Size([12, 1, 6, 448, 304])\n","output:  torch.Size([12, 1, 2, 448, 304])\n","0.031274524891863706 [0.0003910663423254703, 3.290605161973221e-05]\n","Epoch:7/9, current lr:0.0003\n","input:  torch.Size([12, 1, 6, 448, 304])\n","output:  torch.Size([12, 1, 2, 448, 304])\n","0.03127452488837953 [0.0003910663422819031, 3.290605161973221e-05]\n","Epoch:8/9, current lr:0.0003\n","input:  torch.Size([12, 1, 6, 448, 304])\n","output:  torch.Size([12, 1, 2, 448, 304])\n","0.031274524887878706 [0.00039106634227564064, 3.290605161973221e-05]\n","Epoch:9/9, current lr:0.0003\n","input:  torch.Size([12, 1, 6, 448, 304])\n","output:  torch.Size([12, 1, 2, 448, 304])\n","0.03127452488766907 [0.0003910663422730193, 3.290605161973221e-05]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"74ozTn16_a5u","executionInfo":{"status":"ok","timestamp":1615881059999,"user_tz":-540,"elapsed":782,"user":{"displayName":"‍이재승[ 학부휴학 / 통계학과 ]","photoUrl":"","userId":"07334189714045208317"}},"outputId":"98056cc1-0479-4fd8-e14b-86b438aa2095"},"source":["print(loss_hist)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'train': [0.03127452489467292, 0.031274524891185866, 0.031274524889158106, 0.03127452488999857, 0.03127452489040393, 0.031274524891711154, 0.031274524891863706, 0.03127452488837953, 0.031274524887878706, 0.03127452488766907], 'valid': []}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mVnlucAF_bGC"},"source":[""],"execution_count":null,"outputs":[]}]}